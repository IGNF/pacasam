{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Desc\n",
    "- Histo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: PROJ: proj_create_from_database: Open of /home/CGaydon/anaconda3/envs/pacasam/share/proj failed\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import plotly.express as px\n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "sampling_gpkg = Path(\"../outputs/LiPaCConnector/TripleSampler-LiPaCConnector-extract.gpkg\")\n",
    "basename = sampling_gpkg.name\n",
    "df = gpd.read_file(sampling_gpkg)\n",
    "df.head()\n",
    "nb_points_cols = [\n",
    "    \"nb_points_total\",\n",
    "    \"nb_points_sol\",\n",
    "    \"nb_points_bati\",\n",
    "    \"nb_points_vegetation_basse\",\n",
    "    \"nb_points_vegetation_moyenne\",\n",
    "    \"nb_points_vegetation_haute\",\n",
    "    \"nb_points_pont\",\n",
    "    \"nb_points_eau\",\n",
    "    \"nb_points_sursol_perenne\",\n",
    "    \"nb_points_non_classes\",\n",
    "]\n",
    "df = df[\n",
    "    [\n",
    "        \"id\",\n",
    "        \"dalle_id\",\n",
    "        \"date_d_insertion\",\n",
    "        \"date_de_mise_a_jour\",\n",
    "        \"numero_de_colonne\",\n",
    "        \"numero_de_ligne\",\n",
    "        \"date_du_premier_point\",\n",
    "        \"date_du_dernier_point\",\n",
    "        \"denivele\",\n",
    "        \"altitude\",\n",
    "        \"presence_de_surfaces_d_eau\",\n",
    "        \"presence_de_pylones\",\n",
    "        \"presence_d_autoroutes\",\n",
    "        \"is_test_set\",\n",
    "    ]\n",
    "    + nb_points_cols\n",
    "]\n",
    "\n",
    "# TODO: define this as the column name\n",
    "df[\"Split\"] = df[\"is_test_set\"].apply(lambda flag: \"Test\" if flag else \"Train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split               Test  Train\n",
      "total                499   4501\n",
      "sol                  499   4495\n",
      "vegetation_basse     465   4214\n",
      "vegetation_moyenne   462   4171\n",
      "vegetation_haute     450   4122\n",
      "non_classes          207   1996\n",
      "bati                 191   1788\n",
      "eau                   43    337\n",
      "pont                  13    130\n",
      "sursol_perenne        19    125\n"
     ]
    }
   ],
   "source": [
    "def make_class_histogram(df, nb_points_cols):\n",
    "    df_bool = df.copy()\n",
    "    nb_point_col_bool = [nb_point_col.replace(\"nb_points_\", \"\") for nb_point_col in nb_points_cols]\n",
    "    df_bool[nb_point_col_bool] = df_bool[nb_points_cols] > 0\n",
    "    df_bool = df_bool.groupby(\"Split\")[nb_point_col_bool].sum().transpose().sort_values(by=\"Train\", ascending=False)\n",
    "    print(df_bool)\n",
    "    fig = px.bar(df_bool, color=\"Split\", barmode=\"stack\", text_auto=True, title=\"Nombres de patches avec classe présente.\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig_class_hist = make_class_histogram(df, nb_points_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split                  Test  Train\n",
      "presence_d_autoroutes     0      0\n",
      "denivele_heq_45          57    479\n",
      "bati_heq_500            183   1675\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "\n",
    "\n",
    "def make_boolean_descriptor_histogram(df, bool_descriptors_cols: List[str]):\n",
    "    df_bool = df.copy()\n",
    "    df_bool = df_bool.groupby(\"Split\")[bool_descriptors_cols].sum().transpose().sort_values(by=\"Train\", ascending=True)\n",
    "    print(df_bool)\n",
    "    fig = px.bar(df_bool, color=\"Split\", barmode=\"relative\", text_auto=True, title=\"Nombres de patches\", orientation=\"h\")\n",
    "    return fig\n",
    "\n",
    "\n",
    "df[\"denivele_heq_45\"] = df[\"denivele\"] > 45\n",
    "df[\"bati_heq_500\"] = df[\"nb_points_bati\"] > 500\n",
    "fig_bool_desc = make_boolean_descriptor_histogram(df, [\"presence_d_autoroutes\", \"denivele_heq_45\", \"bati_heq_500\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_histograms(df, nb_points_cols, output_path=None):\n",
    "    # Passer à zéro, concernera les classes rares, permet distribution interprétable.\n",
    "    figs = []\n",
    "    df[nb_points_cols] = df[nb_points_cols].replace({0: np.nan})\n",
    "    for c in nb_points_cols:\n",
    "        fig = px.histogram(\n",
    "            df,\n",
    "            x=c,\n",
    "            color=\"Split\",\n",
    "            marginal=\"box\",\n",
    "            hover_data=df.columns,\n",
    "            opacity=0.5,\n",
    "            # text_auto=True,\n",
    "            labels={c: f\"Nombre de points {c.replace('nb_points_','')} (valeurs nulles ignorées)\"},\n",
    "            barmode=\"overlay\",\n",
    "            title=f\"Histogramme du nombres de points : {c.replace('nb_points_','')}\",\n",
    "        )  # or violin, rug\n",
    "        # fig.update_yaxes(title_text='Compte')\n",
    "        figs += [fig]\n",
    "    return figs\n",
    "\n",
    "\n",
    "fig_class_hist_nb_points = make_class_histograms(df, nb_points_cols, output_path=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "\n",
    "\n",
    "def make_scatter_matrix_classes(df, nb_points_cols, norm=None, hide_zeros=True):\n",
    "    \"\"\" \"\"\"\n",
    "    df_norm = df.copy()\n",
    "\n",
    "    if hide_zeros:\n",
    "        df_norm = df_norm.replace(to_replace=0, value=np.nan)\n",
    "\n",
    "    if norm == \"Standardization\":\n",
    "        # Quantilization enables to make classes \"more\" comparable in Farthest point Sampling,\n",
    "        # and respects distribution within each class.\n",
    "        df_norm.loc[:, nb_points_cols] = (df_norm.loc[:, nb_points_cols] - df.loc[:, nb_points_cols].mean()) / df_norm.loc[\n",
    "            :, nb_points_cols\n",
    "        ].std()\n",
    "    elif norm == \"Quantilization\":\n",
    "        # Quantilization enables to fully explore each X vs Y relationship.\n",
    "        qt = QuantileTransformer(n_quantiles=50, random_state=0, subsample=100_000)\n",
    "        df_norm.loc[:, nb_points_cols] = qt.fit_transform(df_norm.loc[:, nb_points_cols].values)\n",
    "\n",
    "    if hide_zeros:\n",
    "        # put zeros back\n",
    "        df_norm.loc[:, nb_points_cols] = df_norm.loc[:, nb_points_cols].fillna(0)\n",
    "\n",
    "    fig = px.scatter_matrix(\n",
    "        df_norm,\n",
    "        dimensions=nb_points_cols,\n",
    "        color=\"Split\",\n",
    "        symbol=\"Split\",\n",
    "        opacity=0.9,\n",
    "        labels={col: col.replace(\"nb_points_\", \"\").replace(\"vegetation\", \"veg\") for col in df.columns},\n",
    "        width=1500,\n",
    "        height=1500,\n",
    "        title=\"Nombres de points\" + (f\" ({norm})\" if norm else \"\") + (\" (zéros ignorés)\" if hide_zeros else \"\"),\n",
    "    )  # remove underscore\n",
    "    fig.update_traces(diagonal_visible=False)\n",
    "\n",
    "    return fig\n",
    "\n",
    "\n",
    "fig_scatter_matrix = make_scatter_matrix_classes(df, nb_points_cols, norm=None)\n",
    "fig_scatter_matrix_standard = make_scatter_matrix_classes(df, nb_points_cols, norm=\"Standardization\")\n",
    "fig_scatter_matrix_quantile = make_scatter_matrix_classes(df, nb_points_cols, norm=\"Quantilization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:8050/\n",
      "\n",
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    }
   ],
   "source": [
    "import plotly.graph_objects as go  # or plotly.express as px\n",
    "\n",
    "import dash\n",
    "from dash import dcc, html\n",
    "from base64 import b64encode\n",
    "import io\n",
    "\n",
    "buffer = io.StringIO()\n",
    "html_bytes = buffer.getvalue().encode()\n",
    "encoded = b64encode(html_bytes).decode()\n",
    "app = dash.Dash()\n",
    "app.layout = html.Div(\n",
    "    [\n",
    "        html.H1(children=\"Dataviz - pacasam sampling\"),\n",
    "        html.Div(f\"Fichier visualizé : {sampling_gpkg}\"),\n",
    "        dcc.Graph(figure=fig_class_hist),\n",
    "        dcc.Graph(figure=fig_bool_desc),\n",
    "    ]\n",
    "    + [html.Div(f\"Histogrammes des nombres de points\")]\n",
    "    + [dcc.Graph(figure=fig) for fig in fig_class_hist_nb_points]\n",
    "    + [html.Div(f\"Matrices - avec différentes normalization (cf. diversity sampling)\")]\n",
    "    + [dcc.Graph(figure=fig_scatter_matrix), dcc.Graph(figure=fig_scatter_matrix_standard), dcc.Graph(figure=fig_scatter_matrix_quantile)]\n",
    ")\n",
    "\n",
    "app.run_server(debug=True, use_reloader=False)  # Turn off reloader if inside Jupyter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Dash' object has no attribute 'save_html'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[249], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m app\u001b[39m.\u001b[39;49msave_html()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Dash' object has no attribute 'save_html'"
     ]
    }
   ],
   "source": [
    "app."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pacasam",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16 | packaged by conda-forge | (main, Feb  1 2023, 21:39:03) \n[GCC 11.3.0]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4e64332e99335d87b7cb4635781ce84b44f87860f5a152e1eeb19b04dddab678"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
